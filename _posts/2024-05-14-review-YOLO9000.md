---
layout: post
title: "YOLO9000: Better, Faster, Stronger Review"
subtitle: 사실은 YOLOv2에 대한 이야기
categories: review
tags: [computer_vision, yolo]
banner:
    image: /images/review/yolo9000/banner.jpeg
---

## Introduction
 그 동안의 모델들은 tag나 category가 꼭 필요했었다. 우리가 주로 사용하는 dataset인 imagenet, coco, pascal visual object class의 경우 수백개에서 수만개의 tag가 필요하게 된다. 이 논문에서는 이미 존재하는 다양한 dataset을 계층적 구조로 보고 함께 사용하며 YOLO9000이라는 모델을 제안하는데, 이 모델은 YOLOv2에 기반을 두고 있다.

## 1. Better
> 더 좋은 성능

 그동안의 detection 모델들은 점점 network가 깊어지는 방향으로 발전해왔는데, 이 모델에서는 총 3가지 방법을 이용하여 모델을 개선 (better)한다.

### 1-1. Batch Normalization
> 각 배치의 평균과 분산을 사용하여 normalization을 진행하는 방법    

참고링크 : <https://yngie-c.github.io/deep%20learning/2021/02/08/batch_normalization/>

-> 해당 방법을 통해 dropout 없이도 overfitting에서 벗어날 수 있었다.    
-> mAP 2% 상승  

### 1-2. High Resolution Classifier
> resolution 즉, 해상도를 높인다.

256x256 보다 작았던 해상도를 448x448 까지 상승  
-> mAP 4% 상승

### 1-3. Convolutional With Anchor Boxes
> Anchor box를 이용한다. - center를 기준으로 object가 있을 것 같은 영역 지정

좌표 대신에 offset을 예측하게 해서 network가 학습하기 쉽게 한다.    
여기서 등장하는 개념이 IOU  
$$IOU = \frac{Overlapping\ Region}{Combined\ Region}$$

single center point를 잡아야 하기 때문에, 448x448였던 network는 416으로 shrink 되고, box의 네 꼭짓점 모두 대신 center만을 생각하면 된다.    
YOLO의 convolution layer은 이미지를 1/32로 downsample하게 되기 때문에 output feature map은 13x13으로 줄어든다.    
Anchor box 도입 전에는 mAP-69.5, recall-81% 였던 수치가 mAP-69.2, recall-88%로 변화되었다. mAP는 줄었지만, recall이 더 많이 증가하였음으로 유의미한 행동이었다.

다만, Anchor box를 도입하면서 발생하는 두 가지 큰 문제가 있는데 이를 해결하여 보자.

#### 1-3-1. Dimension clusters
> 문제 1: box의 dimension을 사람이 지정해줘야 한다

-> 손 대신 k-means를 사용해서 box의 dimension을 지정하자.   
![figure2](/images/review/yolo9000/figure2.jpeg)    
그래프를 보면 number of clusters가 5일 때 model complexity와 recall 간의 가장 합리적인 trade-off를 이룰 수 있다.

![table1](/images/review/yolo9000/table1.jpeg)  
표 1을 봤을 때, Faster-RCNN 논문에서 했던 9개의 centroid를 썼을 때와 Avg IOU가 비슷한 것 또한 관찰할 수 있다.    
-> K-means (cluster 9개)의 효과가 좋았다.

#### 1-3-2. Direct location prediction
> 문제 2: model이 불안정하다.

대부분의 불안정성은 (x,y)를 예측하는 데에서 온다. 기존에 x,y를 예측하는 수식은 아래와 같다.   

$$x=(t_x\times w_a)-x_a$$
$$ y=(t_y\times h_a)-y_a$$
이 식에 따르면, t 값에 따라 box의 위치가 이동하게 되는데, random initialization에 기반하였기 때문에 sensible한 offset을 찾기 위해서는 긴 시간이 소요된다.  
이를 개선하기 위해 새로운 수식을 제안한다.
$$b_x = \sigma (t_x)+c_x$$
$$ b_y = \sigma(t_y)+c_y$$
$$ b_w = p_we^{t_w}$$
$$ b_h = p_he^{t_h}$$
$$ Pr(object)*IOU(b,object) = \sigma(t_o)$$
이 수식에는 constrain이 존재하게 되고, 모델이 훨씬 안정적이게 된다.   
![figure3](/images/review/yolo9000/figure3.jpeg)

### 1-4. Fine-Grained Features
지금까지의 모델에 따르면 13*13 feature map을 사용하게 되는데, 이는 큰 object에 대해서는 좋지만, 오히려 작은 object에 대해서는 좋지 않은 성능을 보이게 된다.    
이를 개선하기 위해 우리는 passthrough layer를 추가하여 higher resolution과 low resolution feature들을 concatenate한다.   
-> 1%의 성능 향상이 있었다.

### 1-5. Multi-Scale Training
> image의 dimension을 주기적으로 (every 10 batches) 교체한다.

1/32로 downsampling하는 과정이 있기 때문에 최소 320에서 최대 608차원까지 option을 주었다.
이를 통해 한 network에서 다양한 resolution에 대한 detection을 예측하게 된다.     
![table3](/images/review/yolo9000/table3.jpeg)  

## 2. Faster
> 더 빠르게 

VGG-16의 경우, 좋은 성능을 보이지만, 쓸데없이 복잡해서 오랜 시간이 필요하다. (224*224 짜리 한 개의 이미지를 계산하는데에 30.69 billion만큼의 floating point 계산이 필요함)

Googlenet을 사용할 경우 속도를 빠르게 하지만, 정확도가 조금 하락한다. 따라서 새로운 모델을 제안한다.

### Darknet-19
VGG와 유사하게 3*3 filter를 사용하고 pooling step 이후에는 채널 수를 2배한다. 이후 GAP를 이용하여 1x1로 compress 한다. 안정적인 학습과, 빠른 수렴 & 정규화를 위해 batch normalization도 사용한다.    
따라서 완성된 모델은 19개의 convolutional layer와 5개의 max pooling layer를 가진다.    
![table6](/images/review/yolo9000/table6.jpeg)   
-> top-1 accuracy: 72.9%, top-5 accuracy: 91.2%

> Training for classification:    
분류를 위해 1000개의 ImageNet 데이터를 이용해 학습시킨다.    
-> top-1 accuracy: 76.5%, top-5 accuracy: 93.3%

> Training for detection:  
마지막 conv. layer를 제거하고, 3x3x1024 conv. layer로 대체 후 1x1 conv. layer를 하나 추가한다.

## 3. Stronger
> YOLOv2를 classification data와 detection data와 함께 학습시켜 YOLO9000 제안

단순히 data를 합칠 경우, 각 데이터셋이 가지고 있는 정보의 수준이 달라 문제가 될 수 있다.  
ex) detection data set: dog, boat와 같이 표시  
ex) classification data set: Yorkshire terrier, Norfolk terrier와 같이 표시  
이럴 경우 dog != yorkshire terrier로 취급될 수 있다.

### Hierarchical classification
> 이를 해결하기 위해 WordTree를 제안한다.

각 노드를 범주로 생각하고, 해당 범주의 하위 범주를 자식 노드로 취급한다. 이때 root node는 physical object로 둔다. 이때 실제로는 object가 무조건 한가지 범주에 들어가는 것은 아니기 때문에 graph 형태로 나타나게 된다.  
ex) yorkshire terrier: physical object > animal >  domestic animal > hunting dog > terrier  
이런 트리에서 특정 범주에 속할 확률은 조건부 확률의 곱을 이용해 계산한다.  


**리뷰 후기: TALK에서 확인해주세요 ^_^**